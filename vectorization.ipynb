{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import ServerlessSpec, Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading environment variables...\n",
      "‚úÖ Pinecone API Key loaded successfully!\n",
      "üîç Checking if Pinecone index 'chatbot' exists...\n",
      "[{\n",
      "    \"name\": \"chatbot\",\n",
      "    \"dimension\": 768,\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"chatbot-momcfao.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"deletion_protection\": \"disabled\"\n",
      "}]\n",
      "‚úÖ Pinecone index 'chatbot' already exists!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Loading environment variables...\")\n",
    "GEMINI_API = os.getenv(\"GEMINI_API\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"‚ùå PINECONE_API_KEY is not set. Please check your environment variables.\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "print(\"‚úÖ Pinecone API Key loaded successfully!\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create or connect to an index\n",
    "index_name = \"chatbot\"\n",
    "print(f\"üîç Checking if Pinecone index '{index_name}' exists...\")\n",
    "print(pc.list_indexes())\n",
    "\n",
    "if index_name not in pc.list_indexes()[0]['name']:\n",
    "    print(f\"üÜï Creating a new Pinecone index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",  # Replace with your model metric\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(f\"‚úÖ Pinecone index '{index_name}' already exists!\")\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_2AusHT_G1Y6hFSc7yrGZEH5CYvcyQNXzDFD5Q7jTEvvxD1RWo1G2Rujm3DCnauje3DEZik\n"
     ]
    }
   ],
   "source": [
    "print(PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading text files from: /home/shtlp_0101/Documents/Project-Based_on_RAG-LLM_model/scraped_city_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load text files\n",
    "folder_path = \"/home/shtlp_0101/Documents/Project-Based_on_RAG-LLM_model/scraped_city_data\"\n",
    "print(f\"üìÇ Loading text files from: {folder_path}\")\n",
    "text_documents = []\n",
    "\n",
    "\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    " \n",
    " \n",
    "#Extract Data From the PDF File\n",
    "def load_txt_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.txt\",\n",
    "                            loader_cls=TextLoader)\n",
    " \n",
    "    documents=loader.load()\n",
    " \n",
    "    return documents\n",
    " \n",
    " \n",
    "extracted_data = load_txt_file(folder_path)\n",
    " \n",
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    " \n",
    " \n",
    "text_chunks = text_split(extracted_data)\n",
    "#Download the Embeddings from HuggingFace\n",
    "def embeddings():\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GEMINI_API)\n",
    "    return embeddings\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading documents to Pinecone...\n",
      "‚úÖ Documents stored in Pinecone!\n",
      "üîç Retriever initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY  # Explicitly set the API key\n",
    "# Correcting the embeddings initialization\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=os.getenv(\"GEMINI_API\"))\n",
    "\n",
    "# Upload documents to Pinecone\n",
    "print(\"üì§ Uploading documents to Pinecone...\")\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,  \n",
    "    index_name=index_name,\n",
    "    embedding=embeddings  # No parentheses here\n",
    ")\n",
    "print(\"‚úÖ Documents stored in Pinecone!\")\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "print(\"üîç Retriever initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API = os.getenv(\"OPENAI_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500,api_key=OPENAI_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=GEMINI_API\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi is a city with a rich history and many famous places. It has ancient roots dating back to the Mahabharata and has been shaped by empires like the Delhi Sultanate and the Mughals. Some of its famous places include Chandni Chowk, Amrit Udyan (formerly known as the Mughal Gardens), and Gurudwara Bangla Sahib.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"famous places in delhi?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chandni Chowk is the bustling heart of Old Delhi, weaving together centuries of history, culture, and commerce. This vibrant market has narrow lanes and chaotic energy. It was built in the 17th century by Mughal Emperor Shah Jahan.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Speciality of chandni chowk?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amritsar's bazaars offer a sensory feast of sizzling street food that will captivate food lovers. The holy 'Mahaprasad', also known as Abhada, is a culinary discovery made in traditional earthen vessels. The delectable cuisine tantalises taste buds with its unique flavours.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what are the best food items there?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
